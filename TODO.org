* TODO Compiling
  See e.g. [[http://api.call-cc.org/doc/utils#def:compile-file][compile-file]]; can we hijack this to make executables?

  #+BEGIN_SRC scheme :tangle compile-test.scm
    (display 'harro)  
  #+END_SRC

  The resultant file will generate a segfault (since it
  unconditionally gives =-s= to =csc=):

  #+BEGIN_SRC scheme :tangle compile-file-test.scm :shebang #!/usr/bin/env chicken-scheme
    (use utils)
    (compile-file "compile-test.scm")
  #+END_SRC

  See e.g.:

  #+BEGIN_SRC scheme
    (define compile-file
      (let ((csc (foreign-value "C_CSC_PROGRAM" c-string))
        (load-file load)
        (path (foreign-value "C_INSTALL_BIN_HOME" c-string)) )
        (lambda (filename #!key options output-file (load #t) verbose)
          (let* ((cscpath (or (file-exists? (make-pathname path csc)) "csc"))
             (tmpfile (and (not output-file) (create-temporary-file "so")))
             (crapshell (eq? (build-platform) 'mingw32))
             (cmd (sprintf "~a~a -s ~a ~a -o ~a~a" 
                (if crapshell "\"" "")
                (qs cscpath)
                (string-intersperse
                 (or options
                 (compile-file-options)))
                (qs filename)
                (qs (or output-file tmpfile))
                (if crapshell "\"" ""))))
        (when verbose (print "  " cmd))
        (let ((status (system cmd)))
          (cond ((zero? status)
             (unless output-file 
               (on-exit
                (lambda ()
                  (handle-exceptions ex #f (delete-file* tmpfile)))))
             (when load
               (let ((f (or output-file tmpfile)))
                 (handle-exceptions ex
                 (begin
                   (delete-file* f)
                   (abort ex))
                   (load-file f)
                   f))))
            (else #f)))))))
  #+END_SRC

  On the other hand:

  #+BEGIN_SRC scheme
    (use setup-api)
    (compile "compile-test.scm")
    (run ("compile-test"))
  #+END_SRC

  Bingo? That way, we can compile arbitrary shit. So, I think we have
  the =lambda= covered. (We’ll embed it in some kind of application
  that parses input line-by-line: =streaming-lambda=? Would be nice to
  have some matchable stuff in there to unpack the line and assign it
  to vars. Maybe that’s for the application to decide.)

  We have the stand-alone file covered (pass it to =compile= via
  =setup-api=).

  Not sure how to deal with locally defined functions that are out of
  scope; we can’t? Either self-contained =lambdas= . . . no, not
  self-contained: even =lambdas= need compiler options. Maybe the
  =streaming-lambda= takes compilation options? That’s somewhat
  interesting: we can do =-X=, =-prelude=, =-postlude=, even
  =-prologue= and =-epilogue=; no to mention =-R=.

  Also, is it possible to run hadoop-streaming in some kind of debug
  mode so we can see what sort of errors emerge? As in: =stdin=,
  =stdout=.

  The alternative to lambda is to write the procedure elsewhere and
  use =-prologue=, &c.; write a library and use =-R=.

  Reduce the key-value pairs in the hadoop form; with special
  reducers in the case of mapper and reducer, keeping it simple at
  first. Let’s just do a pass-through proof of concept, then on to
  the lambda-compile, &c. =streaming-jar= parameter, &c.

  #+BEGIN_SRC scheme :comments link :tangle hadoop-test.scm :shebang #!/usr/bin/env chicken-scheme
  (use shell)

  (define-syntax hadoop
    (syntax-rules ()
      ((_ exp ...)
       (run (hadoop exp ...)))))

  (hadoop fs -ls /)
  #+END_SRC

  =hadoop= is nothing more than =(run (hadoop ...))=, by the way, much
  like =(compile ...)= is =(run (compile ...))=.

  See, for instance:

  #+BEGIN_SRC scheme
    (define (execute explist)
      (define (smooth lst)
        (let ((slst (map ->string lst)))
          (string-intersperse (cons (fixpath (car slst)) (cdr slst)) " ") ) )
      (for-each
       (lambda (cmd)
         (when (run-verbose) (printf "  ~A~%~!" cmd))
         ($system cmd))
       (map smooth explist) ) )
    
    (define-syntax run
      (syntax-rules ()
        ((_ exp ...)
         (execute (list `exp ...)))))
    
    (define-syntax compile
      (syntax-rules ()
        ((_ exp ...)
         (run (csc exp ...)))))
  #+END_SRC
* TODO hadoop-streaming abstraction
  This might requires some =fs= abstractions, too; to delete e.g.
  output directories.

  Maybe a =hadoop= macro that simply passes the elements through?
  E.g.:

  #+BEGIN_SRC scheme
    (hadoop fs -ls ,directory)
  #+END_SRC

  Maybe we can think of some abstractions later. See [[http://hadoop.apache.org/docs/r1.1.2/streaming.html#Streaming%2BCommand%2BOptions][streaming
  options]].

  #+BEGIN_SRC scheme
    ;;; Use some heuristic to find this; possible involving $HADOOP_HOME
    ;;; and a glob such as "contrib/streaming/*.jar"?
    (define streaming-jar (make-parameter #f))
    
    (define (streaming #!optional options))
  #+END_SRC

  Create some kind of job record which takes a scalar or a list (for
  e.g. =file=, which takes multiple invocations); or simply have a
  quasi-quoted macro which converts e.g. keywords into dash-prefixed
  parameters? A =hadoop-{fs,namenode,fsck,job,queue,version,&c.}=
  which do a little of that for you?

  #+BEGIN_SRC scheme
    ;;; Dash things:
    (hadoop fs -ls /)
    
    ;;; Keywords:
    (hadoop fs ls: /)
    (hadoop fs #:ls /)
    
    ;;; Also, which doesn't actually do jack shit:
    (hadoop-fs ls: /)
  #+END_SRC

  This is going to be a trivial wrapper that could just as well be
  accomplished from e.g. shell.

  Is there any way to do something more interesting, such as compiling
  lambdas; making a streaming job look like functional map-reduce in
  the sense that: we compile lambdas, emit objects as strings; emit
  multiple values as something-(e.g.-tab)-delimited strings?

  Can the values corresponding to options be either symbols or
  strings? Why not? Quasi-quote the symbols, if necessary; build a
  string for things like ~stream.map.output.field.separator=.~.

  Mapper is either a symbol (e.g. Java class), string (e.g. path) or a
  lambda: in which case, it gets compiled and the temporary file
  included with =-file=.

  It would be nice to use something like autocompile or another
  memoization mechanism. Optimization.

  Pluggable handlers for e.g. input, output; that do the compilation.
  Otherwise, passthrough?

  This is a beautiful use of the ~=>~ operator in =cond=, by the way;
  from [[http://wiki.call-cc.org/eggref/4/kvlists][kvlists]]:

  #+BEGIN_SRC scheme
    (define (kvlist-ref kvlist key #!optional default)
      (cond ((memq key kvlist) => cadr)
            (else default)))
  #+END_SRC

  A useful case for the truthiness of non-false values.

  Don’t have to use keywords, by the way, for key-value lists;

  #+BEGIN_SRC scheme
    (use kvlists)
    
    ;;; => (a b)
    (kvlist-map values '(a 2 b 3))
  #+END_SRC

  #+BEGIN_SRC scheme
    (hadoop fs :rmr "/books-output")
    ;;; vs.
    (hadoop fs -rmr /books-output)
    
    (hadoop jar ,(streaming-jar)
            ;; This allows quasi-quote;
            -D (mapred.reduce.tasks 2)
            ;; or:
            -D mapred.reduce.tasks=2
            ;; or:
            -D ,(format "mapred.reduce.tasks=~a" 2)
            ;; or:
            -D "mapred.reduce.tasks=2"
            -input /books
            -output /books-output
            -mapper map
            -reducer reduce
            -file map
            -file reduce)
    
    (hadoop-streaming
     :D (mapred.reduce.tasks 2)
     :input "/books"
     :output "/books-output"
     :mapper map
     :reducer reduce)
    
  #+END_SRC

  Can the general =hadoop= macro do the lambda magic? It’s
  streaming-specific, though.

  The other thing is that we can do a procedure-predicate, but how do
  we make sure that procedure is in the scope of the compiled code?
  It’s easy with e.g. a self-contained =lambda=, isn’t it? Damn, we
  almost need an entire document with =use= statements, &c. In that
  case: a string that corresponds to a =.scm= file: compile and
  include? How do we specify compilation flags?

  Do we say: fuck it, the streaming interface is for one-off lambdas?

  This can be used to intersperse string-representations with e.g.
  tab, by the way:

  #+BEGIN_SRC scheme
    (use test)
    
    (call-with-values (lambda () (values 4 5))
      (lambda x (test x '(4 5))))
  #+END_SRC
